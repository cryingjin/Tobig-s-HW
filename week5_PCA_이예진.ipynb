{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반갑습니다 13기 여러분\n",
    "\n",
    "과제를 진행해 볼게요\n",
    "\n",
    "혹시라도 도저히 모르겠거나 해결이 안되신다면 01040493041로 전화주시거나 카톡주세요!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ''' ? ''' 이 있는 부분을 채워주시면 됩니다\n",
    "\n",
    "나는 내 스타일로 하겠다 하시면 그냥 구현 하셔도 됩니다!!\n",
    "\n",
    "참고하셔야 하는 함수들은 링크 달아드렸으니 들어가서 확인해보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) PCA의 과정을 한번 차근차근 밟아 볼거에요 잘 따라 오세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#   기본 모듈들을 불러와 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [95, 91, 66, 94, 68, 63, 12, 73, 93, 51, 13, 70, 63, 63, 97, 56, 67, 96, 75, 6]\n",
    "x2 = [56, 27, 25, 1, 9, 80, 92, 69, 6, 25, 83, 82, 54, 97, 66, 93, 76, 59, 94, 9]\n",
    "x3 = [57, 34, 9, 79, 4, 77, 100, 42, 6, 96, 61, 66, 9, 25, 84, 46, 16, 63, 53, 30]\n",
    "\n",
    "#   설명변수 x1, x2, x3의 값이 이렇게 있네요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((x1,x2,x3),axis=0)\n",
    "\n",
    "#   설명변수들을 하나의 행렬로 만들어 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X.T,columns=['x1','x2','x3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70</td>\n",
       "      <td>82</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56</td>\n",
       "      <td>93</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>67</td>\n",
       "      <td>76</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>96</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75</td>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1  x2   x3\n",
       "0   95  56   57\n",
       "1   91  27   34\n",
       "2   66  25    9\n",
       "3   94   1   79\n",
       "4   68   9    4\n",
       "5   63  80   77\n",
       "6   12  92  100\n",
       "7   73  69   42\n",
       "8   93   6    6\n",
       "9   51  25   96\n",
       "10  13  83   61\n",
       "11  70  82   66\n",
       "12  63  54    9\n",
       "13  63  97   25\n",
       "14  97  66   84\n",
       "15  56  93   46\n",
       "16  67  76   16\n",
       "17  96  59   63\n",
       "18  75  94   53\n",
       "19   6   9   30"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1) 먼저 PCA를 시작하기 전에 항상!!!!!! 데이터를 scaling 해주어야 해요\n",
    "\n",
    "https://datascienceschool.net/view-notebook/f43be7d6515b48c0beb909826993c856/ 를 참고하시면 도움이 될거에요\n",
    "\n",
    "#### 추가로 헷갈렸던 점 정리\n",
    "fit(), transform(), fit_transform 정리\n",
    "https://www.inflearn.com/questions/19038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08573604,  0.02614175,  0.30684189],\n",
       "       [ 0.93801686, -0.86575334, -0.46445467],\n",
       "       [ 0.01477192, -0.92726334, -1.30282049],\n",
       "       [ 1.04880625, -1.66538341,  1.04460382],\n",
       "       [ 0.08863151, -1.41934339, -1.47049366],\n",
       "       [-0.09601747,  0.76426183,  0.97753455],\n",
       "       [-1.97943714,  1.13332186,  1.74883111],\n",
       "       [ 0.2732805 ,  0.42595679, -0.1961776 ],\n",
       "       [ 1.01187645, -1.5116084 , -1.40342439],\n",
       "       [-0.53917504, -0.92726334,  1.61469258],\n",
       "       [-1.94250735,  0.85652683,  0.44098042],\n",
       "       [ 0.16249111,  0.82577183,  0.60865359],\n",
       "       [-0.09601747, -0.03536825, -1.30282049],\n",
       "       [-0.09601747,  1.28709688, -0.76626636],\n",
       "       [ 1.15959564,  0.33369178,  1.21227698],\n",
       "       [-0.35452606,  1.16407687, -0.06203907],\n",
       "       [ 0.05170172,  0.64124181, -1.06807806],\n",
       "       [ 1.12266584,  0.11840676,  0.50804969],\n",
       "       [ 0.3471401 ,  1.19483187,  0.17270336],\n",
       "       [-2.20101593, -1.41934339, -0.5985932 ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_std.T     # transpose 근데 왜 해주는 걸까요? -> 추가설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08573604,  0.93801686,  0.01477192,  1.04880625,  0.08863151,\n",
       "        -0.09601747, -1.97943714,  0.2732805 ,  1.01187645, -0.53917504,\n",
       "        -1.94250735,  0.16249111, -0.09601747, -0.09601747,  1.15959564,\n",
       "        -0.35452606,  0.05170172,  1.12266584,  0.3471401 , -2.20101593],\n",
       "       [ 0.02614175, -0.86575334, -0.92726334, -1.66538341, -1.41934339,\n",
       "         0.76426183,  1.13332186,  0.42595679, -1.5116084 , -0.92726334,\n",
       "         0.85652683,  0.82577183, -0.03536825,  1.28709688,  0.33369178,\n",
       "         1.16407687,  0.64124181,  0.11840676,  1.19483187, -1.41934339],\n",
       "       [ 0.30684189, -0.46445467, -1.30282049,  1.04460382, -1.47049366,\n",
       "         0.97753455,  1.74883111, -0.1961776 , -1.40342439,  1.61469258,\n",
       "         0.44098042,  0.60865359, -1.30282049, -0.76626636,  1.21227698,\n",
       "        -0.06203907, -1.06807806,  0.50804969,  0.17270336, -0.5985932 ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2) 자 그럼 공분산 행렬을 구해볼게요\\\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 설명\n",
    "X_std -> 20 by 3 matrix\n",
    "features -> X_std.T : 3 by  20 matrix  \n",
    "\n",
    "np.cov 공분산을 구해주는 함수는 \n",
    "np.cov(a) 를 넣으면 a가 4 by 3 행렬일 때, (4*3)(3*4) -> (4*4) 행렬을 구해준다.  \n",
    "\n",
    "그래서 np.cov(features)는 (3 by 20)(20 by 3) -> (3*3)\n",
    "features를 넣어줘야 x1,x2,x3의 서로 공분산으로 이뤄진 공분산 행렬을 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3) 이제 고유값과 고유벡터를 구해볼게요\n",
    "\n",
    "방법은 실습코드에 있어요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.48756162, 0.94435407, 0.72597904]), array([[ 0.47018528, -0.85137353, -0.23257022],\n",
      "       [-0.64960236, -0.15545725, -0.74421087],\n",
      "       [-0.59744671, -0.50099516,  0.62614797]]))\n"
     ]
    }
   ],
   "source": [
    "# eigenvalues & eigenvectors\n",
    "# lin.eig 를 사용하면 고유값 먼저 나오고 고유벡터 나옴\n",
    "\n",
    "print(lin.eig(cov_matrix))\n",
    "eigenvalues = lin.eig(cov_matrix)[0]\n",
    "eigenvectors = lin.eig(cov_matrix)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48756162 0.94435407 0.72597904]\n",
      "[[ 0.47018528 -0.85137353 -0.23257022]\n",
      " [-0.64960236 -0.15545725 -0.74421087]\n",
      " [-0.59744671 -0.50099516  0.62614797]]\n"
     ]
    }
   ],
   "source": [
    "print(eigenvalues)\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[0][0] = eigenvalues[0]\n",
    "mat[1][1] = eigenvalues[1]\n",
    "mat[2][2] = eigenvalues[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.48756162, 0.        , 0.        ],\n",
       "       [0.        , 0.94435407, 0.        ],\n",
       "       [0.        , 0.        , 0.72597904]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가설명  \n",
    "0으로 채워진 정방행렬 mat를 만들고 대각값들을 고유값들을 가지도록 만들어줌.  \n",
    "결국 고유벡터와 고유값 matrix를 가지게되었음.  \n",
    "### Av = lambda*v\n",
    "- 공분산행렬 A = X_std\n",
    "- v = 고유벡터 eigenvectors\n",
    "- lambda * I (identity) = mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4) 자 이제 고유값 분해를 할 모든 준비가 되었어요 고유값 분해의 곱으로 원래 공분산 행렬을 구해보세요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html 를 참고해서 행렬 끼리 곱하시면 됩니다\n",
    "\n",
    "행렬 곱으로 eigenvector x mat x eigenvector.T 하면 될거에요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강의자료 - PCA 공분산 행렬의 스펙트럼 분해 참고  \n",
    "공분산행렬 시그마는 PAP(T)로 분해된다.  \n",
    "P는 고유벡터의 열로 구성된 행렬  \n",
    "A는 고유값을 대각원소로 하는 대각행렬(여기서는 mat)  \n",
    "\n",
    "![스펙트럼 분해](spectrum.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(eigenvectors,mat),eigenvectors.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-5) 마지막으로 고유 벡터 축으로 값을 변환해 볼게요\n",
    "\n",
    "함수로 한번 정의해 보았어요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_coordinates(X,eigenvectors):\n",
    "    for i in range(eigenvectors.shape[0]):\n",
    "        if i == 0:\n",
    "            new = [X.dot(eigenvectors.T[i])]\n",
    "            # X의 원소와 eigenvectors의 원소 차례로 내적.\n",
    "        else:\n",
    "            # print(new)\n",
    "            new = np.concatenate((new,[X.dot(eigenvectors.T[i])]),axis=0)\n",
    "            \n",
    "    return new.T\n",
    "\n",
    "# 모든 고유 벡터 축으로 데이터를 projection한 값입니다\n",
    "# projection -> 기본데이터에다가 고유벡터들을 내적해줌. \n",
    "# for i  사용해서 [0] 과 [1],[2] 나눈이유는 배열 쌓아올리기 위해서...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coordinates(X_std,eigenvectors)\n",
    "\n",
    "# 새로운 축으로 변환되어 나타난 데이터들입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = new_coordinates(X_std,eigenvectors)\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) PCA를 구현해 보세요\n",
    "\n",
    "위의 과정을 이해하셨다면 충분히 하실 수 있을거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def MYPCA(X,number):\n",
    "    scaler = StandardScaler()\n",
    "    x_std = scaler.fit_transform(X)\n",
    "    features = x_std.T\n",
    "    cov_matrix = np.cov(features)\n",
    "    \n",
    "    eigenvalues = lin.eig(cov_matrix)[0]\n",
    "    eigenvectors = lin.eig(cov_matrix)[1]\n",
    "    \n",
    "    new_coordinates(x_std,eigenvectors)      # projection\n",
    "    \n",
    "    new_coordinate = new_coordinates(x_std,eigenvectors)      # projection해서 새롭게 얻은 값의 array\n",
    "    \n",
    "    index = eigenvalues.argsort()      # 고유값을 오름차순으로 sort해줌 반환값은 본래 배열의 위치\n",
    "    index = list(index)\n",
    "    \n",
    "          \n",
    "    for i in range(number):\n",
    "        if i==0:\n",
    "            new = [new_coordinate[:,index.index(i)]]     # ?\n",
    "        else:\n",
    "            new = np.concatenate(([new_coordinate[:,index.index(i)]],new),axis=0)\n",
    "    return new.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = MYPCA(X,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "달라졌는데, 어디가?\n"
     ]
    }
   ],
   "source": [
    "if b.all == a.all:\n",
    "    print(\"안달라졌는데\")\n",
    "else: \n",
    "    print(\"달라졌는데, 어디가?\")\n",
    "    \n",
    "    #  안달라졌는지 알았는데 달라지긴 했나봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3)\n",
    "\n",
    "# 새로운 축으로 잘 변환되어서 나타나나요?\n",
    "# 위에서 했던 PCA랑은 차이가 있을 수 있어요 왜냐하면 위에서는 고유값이 큰 축 순서로 정렬을 안했었거든요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) sklearn이랑 비교를 해볼까요?\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31019368, -1.08215716, -0.07983642],\n",
       "       [-1.28092404, -0.43132556,  0.13533091],\n",
       "       [-1.38766381,  0.78428014, -0.12911446],\n",
       "       [-0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [-1.84222365,  0.88189889,  0.11493111],\n",
       "       [ 1.12563709, -0.52680338,  0.06564012],\n",
       "       [ 2.71174416,  0.63290138,  0.71195473],\n",
       "       [ 0.03100441, -0.20059783, -0.50339479],\n",
       "       [-2.29618509,  0.07661447,  0.01087174],\n",
       "       [ 0.61585248, -0.205764  ,  1.82651199],\n",
       "       [ 1.73320252,  1.29971699,  0.09045178],\n",
       "       [ 0.82366049, -0.57164535, -0.27123176],\n",
       "       [-0.75619512,  0.73995175, -0.76710616],\n",
       "       [ 0.42344386,  0.26555394, -1.41533681],\n",
       "       [ 0.39581307, -1.64646874,  0.24104031],\n",
       "       [ 0.88581498,  0.15195119, -0.82271209],\n",
       "       [-0.24587691,  0.39139878, -1.15801831],\n",
       "       [-0.14741103, -1.22874561, -0.03110396],\n",
       "       [ 0.7161265 , -0.56781471, -0.86180345],\n",
       "       [-0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit_transform(X_std)\n",
    "# if n_components is not set all components are kept: n_components == min(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) MNIST data에 적용을 해볼게요!\n",
    "\n",
    "mnist data를 따로 내려받지 않게 압축파일에 같이 두었어요~!!!\n",
    "\n",
    "mnist-original.mat 파일과 같은 위치에서 주피터 노트북을 열어주세요~!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from scipy import io\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "# fetch_openml\n",
    "# mnist 손글씨 데이터를 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = io.loadmat('mnist-original.mat') \n",
    "X = mnist['data'].T\n",
    "y = mnist['label'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data information\n",
    "\n",
    "# 7만개의 작은 숫자 이미지\n",
    "# 행 열이 반대로 되어있음 -> 전치\n",
    "# grayscale 28x28 pixel = 784 feature\n",
    "# 각 picel은 0~255의 값\n",
    "# label = 1~10 label이 총 10개인거에 주목하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data를 각 픽셀에 이름붙여 표현\n",
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df에 라벨 y를 붙여서 데이터프레임 생성\n",
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995       0       0       0       0       0       0       0       0       0   \n",
       "69996       0       0       0       0       0       0       0       0       0   \n",
       "69997       0       0       0       0       0       0       0       0       0   \n",
       "69998       0       0       0       0       0       0       0       0       0   \n",
       "69999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "69995       0  ...         0         0         0         0         0   \n",
       "69996       0  ...         0         0         0         0         0   \n",
       "69997       0  ...         0         0         0         0         0   \n",
       "69998       0  ...         0         0         0         0         0   \n",
       "69999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783    y  \n",
       "0             0         0         0         0  0.0  \n",
       "1             0         0         0         0  0.0  \n",
       "2             0         0         0         0  0.0  \n",
       "3             0         0         0         0  0.0  \n",
       "4             0         0         0         0  0.0  \n",
       "...         ...       ...       ...       ...  ...  \n",
       "69995         0         0         0         0  9.0  \n",
       "69996         0         0         0         0  9.0  \n",
       "69997         0         0         0         0  9.0  \n",
       "69998         0         0         0         0  9.0  \n",
       "69999         0         0         0         0  9.0  \n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지금까지 배운 여러 머신러닝 기법들이 있을거에요\n",
    "\n",
    "4-1) train_test_split을 통해 데이터를 0.8 0.2의 비율로 분할 해 주시고요\n",
    "\n",
    "4-2) PCA를 이용하여 mnist data를 축소해서 학습을 해주세요 / test error가 제일 작으신 분께 상품을 드리겠습니다 ^0^\n",
    "\n",
    "특정한 틀 없이 자유롭게 하시면 됩니다!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 스케일링 -> split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=42)\n",
    "X_train2 = scaler.fit_transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 나누고 스케일하는 것 유의!\n",
    "train 셋에는 fit_transform 이고  \n",
    "test 셋에는 train셋에서 얻은 값을 적용만한는 transform이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA 사용하기위해 하이퍼파라미터 찾기\n",
    "### n_components 설정을 위해 참고\n",
    "https://towardsdatascience.com/an-approach-to-choosing-the-number-of-components-in-a-principal-component-analysis-pca-3b9f3d6e73fe\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html?highlight=pca#sklearn.decomposition.PCA  \n",
    "\n",
    "디폴트는 n_components == min(n_samples,n_features) 로 모든 구성요소의 유지인듯. 정수값을 넣어줌.   \n",
    "다른 옵션으로 n_components == mle나 svd_solver =='full'있음.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fitting the PCA algorithm with our Data\n",
    "pca = PCA().fit(X_train2)\n",
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Pulsar Dataset Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### elbow point는 300정도로 보이지만 너무 커서 여러가지 조정해봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.938112424860906"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 300)\n",
    "X_pca = pca.fit_transform(X_train2)\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA() #주성분 개수 지정하지 않고 클래스생성\n",
    "pca.fit(X_train2)  #주성분 분석\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.70) + 1 # 분산의 설명량이 70%이상 되는 차원의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분산의 설명량이 60%이상 되는 차원의 수\n",
    "num_d2 = np.argmax(cumsum >= 0.60) + 1 \n",
    "\n",
    "num_d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고  \n",
    "http://textmining.kr/?p=362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_components는 95쯤으로 생각하고 pca진행\n",
    "\n",
    "pca_95 = PCA(n_components = 95)\n",
    "X_pca95 = pca_95.fit_transform(X_train2)\n",
    "X_test95 = pca_95.transform(X_test2)\n",
    "\n",
    "# test셋은 pca가 안되어 있어서 모델을 예측(pred)할때 오류가 남.\n",
    "# X_test에도 pca적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56000, 95), (14000, 95))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_pca95),np.shape(X_test95)     # 주성분의 갯수가 300개로 줄어듬. feature의 갯수 300개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized pca\n",
    "rnd_pca = PCA(svd_solver='randomized',random_state=42)\n",
    "\n",
    "rnd_pca.fit(X_train2)  \n",
    "cumsum = np.cumsum(rnd_pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_rnd_d = np.argmax(cumsum >= 0.95) + 1 # 분산의 설명량이 95%이상 되는 차원의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rnd_d     # 그냥 pca와 비슷하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure()\\nplt.plot(X_pca,y_train)\\nplt.xlabel('X_pca')\\nplt.ylabel('y_train') \\nplt.title('X_pca 시각화')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터의 분포를 한번 살펴보기 위해서 시각화해보려고 했지만 차원이 300이라 안됨!\n",
    "# 좋은 방법있으면 알려주세요~!\n",
    "\n",
    "\"\"\"\n",
    "plt.figure()\n",
    "plt.plot(X_pca,y_train)\n",
    "plt.xlabel('X_pca')\n",
    "plt.ylabel('y_train') \n",
    "plt.title('X_pca 시각화')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from time import sleep\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lgbm.fit(X_pca95,y_train.ravel())\n",
    "# %time을 통해 피팅에 걸리는 시간 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:\n",
      "0.9498571428571428\n",
      "Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.98      1349\n",
      "         1.0       0.99      0.99      0.99      1581\n",
      "         2.0       0.94      0.95      0.94      1400\n",
      "         3.0       0.93      0.94      0.93      1434\n",
      "         4.0       0.94      0.96      0.95      1328\n",
      "         5.0       0.94      0.92      0.93      1286\n",
      "         6.0       0.98      0.97      0.97      1407\n",
      "         7.0       0.95      0.96      0.96      1476\n",
      "         8.0       0.93      0.93      0.93      1391\n",
      "         9.0       0.93      0.91      0.92      1348\n",
      "\n",
      "    accuracy                           0.95     14000\n",
      "   macro avg       0.95      0.95      0.95     14000\n",
      "weighted avg       0.95      0.95      0.95     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgbm.predict(X_test95)\n",
    "\n",
    "print('Accuracy score:')\n",
    "print(accuracy_score(y_test.ravel(),y_pred))\n",
    "print('Classification_report:')\n",
    "print(classification_report(y_test.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] boosting_type=gbdt, learning_rate=0.05 ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=gbdt, learning_rate=0.05, score=(train=0.965, test=0.927), total= 1.5min\n",
      "[CV] boosting_type=gbdt, learning_rate=0.05 ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=gbdt, learning_rate=0.05, score=(train=0.966, test=0.927), total= 1.6min\n",
      "[CV] boosting_type=gbdt, learning_rate=0.05 ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=gbdt, learning_rate=0.05, score=(train=0.965, test=0.925), total= 1.8min\n",
      "[CV] boosting_type=gbdt, learning_rate=0.1 ...........................\n",
      "[CV]  boosting_type=gbdt, learning_rate=0.1, score=(train=0.997, test=0.946), total= 1.7min\n",
      "[CV] boosting_type=gbdt, learning_rate=0.1 ...........................\n",
      "[CV]  boosting_type=gbdt, learning_rate=0.1, score=(train=0.997, test=0.948), total= 1.7min\n",
      "[CV] boosting_type=gbdt, learning_rate=0.1 ...........................\n",
      "[CV]  boosting_type=gbdt, learning_rate=0.1, score=(train=0.997, test=0.947), total= 1.9min\n",
      "[CV] boosting_type=gbdt, learning_rate=0.15 ..........................\n",
      "[CV]  boosting_type=gbdt, learning_rate=0.15, score=(train=1.000, test=0.952), total= 2.0min\n",
      "[CV] boosting_type=gbdt, learning_rate=0.15 ..........................\n",
      "[CV]  boosting_type=gbdt, learning_rate=0.15, score=(train=1.000, test=0.954), total= 2.0min\n",
      "[CV] boosting_type=gbdt, learning_rate=0.15 ..........................\n",
      "[CV]  boosting_type=gbdt, learning_rate=0.15, score=(train=1.000, test=0.953), total= 2.0min\n",
      "[CV] boosting_type=gbdt, learning_rate=0.2 ...........................\n",
      "[CV]  boosting_type=gbdt, learning_rate=0.2, score=(train=1.000, test=0.956), total= 2.0min\n",
      "[CV] boosting_type=gbdt, learning_rate=0.2 ...........................\n",
      "[CV]  boosting_type=gbdt, learning_rate=0.2, score=(train=1.000, test=0.957), total= 2.1min\n",
      "[CV] boosting_type=gbdt, learning_rate=0.2 ...........................\n",
      "[CV]  boosting_type=gbdt, learning_rate=0.2, score=(train=1.000, test=0.957), total= 2.0min\n",
      "[CV] boosting_type=dart, learning_rate=0.05 ..........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.05, score=(train=0.931, test=0.901), total= 2.1min\n",
      "[CV] boosting_type=dart, learning_rate=0.05 ..........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.05, score=(train=0.931, test=0.903), total= 1.8min\n",
      "[CV] boosting_type=dart, learning_rate=0.05 ..........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.05, score=(train=0.928, test=0.897), total= 1.8min\n",
      "[CV] boosting_type=dart, learning_rate=0.1 ...........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.1, score=(train=0.964, test=0.926), total= 1.8min\n",
      "[CV] boosting_type=dart, learning_rate=0.1 ...........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.1, score=(train=0.964, test=0.927), total= 1.9min\n",
      "[CV] boosting_type=dart, learning_rate=0.1 ...........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.1, score=(train=0.964, test=0.925), total= 2.2min\n",
      "[CV] boosting_type=dart, learning_rate=0.15 ..........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.15, score=(train=0.984, test=0.939), total= 2.1min\n",
      "[CV] boosting_type=dart, learning_rate=0.15 ..........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.15, score=(train=0.985, test=0.941), total= 1.6min\n",
      "[CV] boosting_type=dart, learning_rate=0.15 ..........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.15, score=(train=0.984, test=0.938), total= 1.6min\n",
      "[CV] boosting_type=dart, learning_rate=0.2 ...........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.2, score=(train=0.995, test=0.947), total= 1.2min\n",
      "[CV] boosting_type=dart, learning_rate=0.2 ...........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.2, score=(train=0.995, test=0.947), total= 1.2min\n",
      "[CV] boosting_type=dart, learning_rate=0.2 ...........................\n",
      "[CV]  boosting_type=dart, learning_rate=0.2, score=(train=0.995, test=0.946), total= 1.2min\n",
      "[CV] boosting_type=goss, learning_rate=0.05 ..........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.05, score=(train=0.967, test=0.930), total=  43.1s\n",
      "[CV] boosting_type=goss, learning_rate=0.05 ..........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.05, score=(train=0.967, test=0.930), total=  42.6s\n",
      "[CV] boosting_type=goss, learning_rate=0.05 ..........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.05, score=(train=0.967, test=0.928), total=  48.6s\n",
      "[CV] boosting_type=goss, learning_rate=0.1 ...........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.1, score=(train=0.997, test=0.949), total=  45.5s\n",
      "[CV] boosting_type=goss, learning_rate=0.1 ...........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.1, score=(train=0.997, test=0.949), total=  50.7s\n",
      "[CV] boosting_type=goss, learning_rate=0.1 ...........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.1, score=(train=0.997, test=0.949), total=  57.9s\n",
      "[CV] boosting_type=goss, learning_rate=0.15 ..........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.15, score=(train=1.000, test=0.955), total=  46.5s\n",
      "[CV] boosting_type=goss, learning_rate=0.15 ..........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.15, score=(train=1.000, test=0.956), total=  44.2s\n",
      "[CV] boosting_type=goss, learning_rate=0.15 ..........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.15, score=(train=1.000, test=0.955), total=  43.5s\n",
      "[CV] boosting_type=goss, learning_rate=0.2 ...........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.2, score=(train=1.000, test=0.956), total=  48.2s\n",
      "[CV] boosting_type=goss, learning_rate=0.2 ...........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.2, score=(train=1.000, test=0.959), total=  44.4s\n",
      "[CV] boosting_type=goss, learning_rate=0.2 ...........................\n",
      "[CV]  boosting_type=goss, learning_rate=0.2, score=(train=1.000, test=0.958), total=  48.0s\n",
      "[CV] boosting_type=rf, learning_rate=0.05 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.05, score=(train=nan, test=nan), total=   0.8s\n",
      "[CV] boosting_type=rf, learning_rate=0.05 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.05, score=(train=nan, test=nan), total=   0.8s\n",
      "[CV] boosting_type=rf, learning_rate=0.05 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.05, score=(train=nan, test=nan), total=   0.9s\n",
      "[CV] boosting_type=rf, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.1, score=(train=nan, test=nan), total=   0.8s\n",
      "[CV] boosting_type=rf, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.1, score=(train=nan, test=nan), total=   0.9s\n",
      "[CV] boosting_type=rf, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.1, score=(train=nan, test=nan), total=   0.8s\n",
      "[CV] boosting_type=rf, learning_rate=0.15 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.15, score=(train=nan, test=nan), total=   0.8s\n",
      "[CV] boosting_type=rf, learning_rate=0.15 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.15, score=(train=nan, test=nan), total=   0.8s\n",
      "[CV] boosting_type=rf, learning_rate=0.15 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.15, score=(train=nan, test=nan), total=   0.8s\n",
      "[CV] boosting_type=rf, learning_rate=0.2 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.2, score=(train=nan, test=nan), total=   0.8s\n",
      "[CV] boosting_type=rf, learning_rate=0.2 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.2, score=(train=nan, test=nan), total=   0.8s\n",
      "[CV] boosting_type=rf, learning_rate=0.2 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 55.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  boosting_type=rf, learning_rate=0.2, score=(train=nan, test=nan), total=   0.9s\n",
      "Wall time: 56min 28s\n",
      "best parameters:{'boosting_type': 'goss', 'learning_rate': 0.2}\n",
      "best score:0.9574464355597208\n"
     ]
    }
   ],
   "source": [
    "# lightGBM의 하이퍼파라미터를 그리드서치로 찾아보자\n",
    "\n",
    "param_grid = {'boosting_type':['gbdt','dart','goss','rf'],'learning_rate':[0.05,0.1,0.15,0.2]}\n",
    "grid = GridSearchCV(lgbm,param_grid,cv=3,return_train_score=True,scoring = 'accuracy',verbose=3)\n",
    "%time grid.fit(X_pca95,y_train.ravel())\n",
    "\n",
    "print(\"best parameters:{}\".format(grid.best_params_))\n",
    "print(\"best score:{}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='goss', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.2, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters:{'boosting_type': 'goss', 'learning_rate': 0.2}\n",
    "# best score:0.9574464355597208\n",
    "\n",
    "# best 파라미터를 사용해서 튜닝하고 다시 한번 light gbm\n",
    "lgbm = LGBMClassifier(boosting_type='goss',learning_rate=0.2)\n",
    "\n",
    "%time lgbm.fit(X_pca95,y_train.ravel())\n",
    "# %time을 통해 피팅에 걸리는 시간 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:\n",
      "0.9608571428571429\n",
      "Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.98      1349\n",
      "         1.0       0.99      0.99      0.99      1581\n",
      "         2.0       0.95      0.96      0.96      1400\n",
      "         3.0       0.95      0.95      0.95      1434\n",
      "         4.0       0.96      0.97      0.97      1328\n",
      "         5.0       0.96      0.94      0.95      1286\n",
      "         6.0       0.98      0.97      0.98      1407\n",
      "         7.0       0.96      0.97      0.97      1476\n",
      "         8.0       0.94      0.95      0.94      1391\n",
      "         9.0       0.94      0.93      0.93      1348\n",
      "\n",
      "    accuracy                           0.96     14000\n",
      "   macro avg       0.96      0.96      0.96     14000\n",
      "weighted avg       0.96      0.96      0.96     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgbm.predict(X_test95)\n",
    "\n",
    "print('Accuracy score:')\n",
    "print(accuracy_score(y_test.ravel(),y_pred))\n",
    "print('Classification_report:')\n",
    "print(classification_report(y_test.ravel(),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM 사용하고 하이퍼파라미터 튜닝을 통해서 accuracy 0.96까지 끌어올림."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 파라미터 대강 설정\n",
    "svc_temp = SVC(C=10,kernel='linear',gamma='scale')\n",
    "svc_temp.fit(X_pca,y_train.ravel())\n",
    "\n",
    "y_pred = svm_temp.predict(X_pca)\n",
    "\n",
    "print('Accuracy Score:')\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고 \n",
    "https://stackoverflow.com/questions/34165731/a-column-vector-y-was-passed-when-a-1d-array-was-expected  \n",
    "\n",
    ".values will give the values in an array. (shape: (n,1)\n",
    "\n",
    ".ravel will convert that array shape to (n, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM 단점\n",
    "SVM 을 이 데이터셋에 사용하는 것은 잘못된 선택이었던 것 같다.  \n",
    "데이터가 56000개이고 gridsearch를 진행하니 18케이스 중에 찾는 것도 한 케이스당 6분이 걸릴 정도로 매우 느리다.  \n",
    "그리드 서치를 포기하고 아무 파라미터로 하고 돌려도 봤는데 학습되다가 컴퓨터가 멈춰서 포기했다.  \n",
    "반면 그리드서치 중에 accuracy score는 0.9 정도로 높게 나오는데 과적합되는 것 같다.  \n",
    "단점을 보완하기 위해 트리 기반의 모델을 많이 사용한다고 하니 트리기반의 모델을 사용해보겠다.\n",
    "\n",
    "시도해볼 모델 : XGboost, 나이브베이즈 (선형일때, 큰 데이터셋에 시도해볼만하다고함.)\n",
    "#### 데이터가 10000개 넘어가면 svm 자제 하기 명심 명심....!\n",
    "\n",
    "추가 svm 참고 사이트  \n",
    "https://nonmeyet.tistory.com/entry/Python-SVM-%EC%84%9C%ED%8F%AC%ED%8A%B8-%EB%B0%B1%ED%84%B0-%EB%A8%B8%EC%8B%A0%EC%9D%98-%EC%A0%95%EC%9D%98-%EB%B0%8F-%EC%98%88%EC%8B%9C-%EC%BD%94%EB%93%9Csklearn-2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 따라해보기\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier()\n",
    "%time model_rf.fit(X_pca95,y_train.ravel())\n",
    "\n",
    "y_pred_rf = model_rf.predict(X_test95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:\n",
      "0.9449285714285715\n",
      "Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.97      1349\n",
      "         1.0       0.99      0.98      0.98      1581\n",
      "         2.0       0.93      0.95      0.94      1400\n",
      "         3.0       0.90      0.94      0.92      1434\n",
      "         4.0       0.94      0.97      0.95      1328\n",
      "         5.0       0.95      0.91      0.93      1286\n",
      "         6.0       0.97      0.97      0.97      1407\n",
      "         7.0       0.94      0.95      0.94      1476\n",
      "         8.0       0.94      0.91      0.92      1391\n",
      "         9.0       0.93      0.89      0.91      1348\n",
      "\n",
      "    accuracy                           0.94     14000\n",
      "   macro avg       0.94      0.94      0.94     14000\n",
      "weighted avg       0.95      0.94      0.94     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:')\n",
    "print(accuracy_score(y_test.ravel(),y_pred_rf.ravel()))\n",
    "print('Classification_report:')\n",
    "print(classification_report(y_test.ravel(),y_pred_rf.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist 데이터셋으로 디폴트된 값으로 랜덤포레스트를 시키면 0.945의 성능을 보임."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python36564bitbaseconda5e4e95bad6fc48a495fff358f53d205a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
